# Visualizations
This is a more detailed description of each visualization we made and the data manipulation and processing we did to create these visualizations. The code and additional documentation for each visualization can be found in the notebooks of this folder, listed in the same order as they are below. Because of data privacy reasons, the code in those notebooks will contain synthetic data with 100 data observations. The visualizations will not look as complete as they do in the animated GIFs displayed on the main repository README once ran, but the code is there for the user to see the synthetic data code as a reference for when they want to create these visualizations using their own data.

## Sociality vs. Age of Subreddits
This interactive visualization below displays the relationship between sociality and age of subreddits, grouped by subreddit cluster, in a scatterplot. The data we used specifically for this visualization contains information about the demographics of various subreddits. Each subreddit is grouped into a general cluster. For each demographic, the higher the percentile number or the larger the raw number, the more extreme the value is, and vice versa. For this visualization, we are using the raw data for sociality and age. The user can see the relationship between sociality and age for each subreddit cluster in the format of a scatterplot by navigating the interactive dropdown menu. The user can also hover over each point to see the specific subreddit and its corresponding sociality and age values.

You can compare any two variables from the subreddit dataset with this interactive scatterplot. To change the variables that are being compared in the visualization, change the variable names for the kdims parameter as well as for the hover key.

## Worldwide Location Reveals of Reddit Users by Day of the Week
The interactive visualization below displays when users revealed their locations on Reddit by hour of day and day of the week, overlayed onto a map of the world.

Before we could make the visualization, we first had to do some data manipulations to convert the given time (Unix UTC time) into human readable time that is also adjusted to timezone, using functions from the `datetime`, `pandas`, and `pytz` libraries. The longitude-latitude location data given is referring to the approximate location of where the user revealed their location to be on Reddit.

The user can select which day of the week or hour of day to look at with the dropdown menus that are a part of the visualization. The user can also hover over each point on the map to see the username, longitude/latitude and timezone.

## Affluence of Reddit Users Around the World
This interactive bubble map visualization displays the affluence of users based on which subreddit they posted under overlayed onto a map of the world based on where they revealed their location, grouped by subreddit cluster.  

The Reddit post data files we had were broken up into many `.geo.tsv` files, organized by the letter or number that the usernames begin with. We have combined all of these files into one big file. We have also merged parts of other datasets to this big dataset by adding specifically the subreddit cluster name and affluence percentile from the subreddit demographics dataset, as well as the longitude/latitude and timezone of each user from the geographical dataset. Because of the limitations of the `Python 3 kernel` with plotting very large amounts of points, we dropped any `NaN` and duplicate observations to reduce overplotting and to make the visualization look cleaner. After doing this data cleaning, we saved that file into a parquet file so that we don't need to clean the dataset each time we run the code.

This interactive visualization has a dropdown menu which will allow the user to see the affluence geographically visualized for each of the 30 subreddit clusters. The affluence measured was provided in the dataset as a percentile, so the larger the bubble displayed, the higher the percentile value and thus the higher the affluence, and vice versa. The user can also hover over each bubble to see the corresponding subreddit, subreddit cluster name, and affluence percentile value.

## Relative Frequencies of Posts by Hour of Day
This interactive stacked bar chart visualization displays the relative frequencies of Reddit posts for each hour of the day (timezone adjusted), grouped by each subreddit cluster. 

The Reddit post data files we had were broken up into many `.geo.tsv` files, organized by the letter or number that the usernames begin with. We have combined all of these files into one big file. We have combined all of these files into one big file. We have also merged parts of other datasets to this big dataset by adding the subreddit cluster name from the subreddit demographics dataset, as well as the timezone of each user from the geographical dataset. 

The posting time of each Reddit post was initially given to us in Unix format (number of seconds passed since January 1st, 1970), so we used functions from the dateime Python library to iterate through the combined dataset, convert each Unix time into a human readable time, adjust each time by the given timezone, and then extract out the hour of day. To expedite this process, before running the time conversions, we saved only the posting time, subreddit cluster name, and timezone columns from the combined dataset into a temporary dataframe, and when running the time conversions, we only extracted out the hour because that was that was the only time component we were interested in. After the conversions ran, we saved the dataframe as a parquet file so we would only need to run this conversion once and then we can readily use this data.

## Worldwide Reddit Post Activity
This interactive visualization made with graphical processing units (GPUs) displays all of the Reddit posts in our dataset by when they were posted (hour and day of the week in Universal Time) and where they were posted (location reveal of author).

The Reddit post data files we had were broken up into many `.geo.tsv` files, organized by the letter or number that the usernames begin with. We have combined all of these files into one big file. We have combined all of these files into one big file. We have also merged parts of other datasets to this big dataset by adding the subreddit cluster name from the subreddit demographics dataset, as well as the longitude/latitude of each user from the geographical dataset. We stored this combined file into a `parquet` file, a file format that we found makes reading in files much faster.

The posting time of each Reddit post was initially given to us in Unix time format (number of seconds passed since January 1st, 1970), so we used functions from the `datetime`, `pytz`, and `pandas` Python libraries to iterate through the combined dataset and convert each Unix time into a human readable time, and then extract out the hour of day and day of the week. We did this iteration in sections by dividing up the combined dataset by small groups of subreddit clusters. With this combined dataset, for each Reddit post, we now can identify author, time posted, location, and subreddit cluster name. We had to convert the hour variable in the dataset so that the multiselect tool in the GPU visualization would work properly. We also had to assign each day of the week to a number between 0 and 6 inclusive to make a label map so that the day of the week dropdown in the visualization would work properly. We then only extracted the columns in the dataset that we wanted: longitude, latitude, hour, day of the week (converted to a number). Also, in order for the map to properly display behind the data points, we also converted the longitude/latitude coordinates to Mercator (x, y) coordinates. We saved all of these data manipulations into a temporary file just with the geographic coordinates, hour of day, and day of the week as a number, so that we wouldn't have to run the data manipulation code over and over again.

On the left of the visualization, there is a sidebar that displays the number of data points currently selected. To the right of the visualization there are tools that allow the user to select or zoom into a specific area of the map. There is also an hour of day multiselect tool where the user can select one or more hour of the day to look at by shift + right-clicking on the desired hours. In addition, there is a day of the week dropdown where the user can select a specific day of the week to look at. The combination of the dropdown and the multiselect tools can allow the user to see the distribution of posts by hour of day for each day of the week or for the entire dataset.

## Affluence and Frequency of Posting of Reddit Users by US State
Using the data author locations and demographic data files we created interactive choropleth map visualizations showing posting frequency and age/affluence/gender by state in the United States.

To produce our US choropleth visualizations we first had to load the geographic location data (country/city) file and change the header of the columns into ‘Author’, ‘Country’, ‘State’, and ‘City’ using the `.rename()` function. Then we loaded the combined Reddit post information file, dropped duplicate authors, and only selected the columns that were essential for our visualization ('author', 'subreddit', 'cluster_name', 'long', and 'lat'). We then merged both dataframes using the ‘author’ column, used the `.value_counts()` function to count the frequency of each US state and finally used a dictionary to add a column with state abbreviations (e.g 'Florida': 'FL'). With this final dataframe we were able to create the US post frequency choropleth map. We then kept on wrangling the data to create visualizations for the US with the demographic information. We started by loading the demographic information, changing the name of the column titled ‘name’ to ‘subreddit’, and selected only the useful columns for this visualization. Then we merged this dataframe with the one we used to create the US state frequency visualization. In addition, we created a separate dataframe calculating the mean affluence percentile of every state, which we then merged onto the previous dataframe. We made sure to fill any `NaN` values with the proper state abbreviation and then created the visualization.

The first choropleth visualization allows the user to see how many Reddit posts where made in each state and see which states had a higher post frequency when compared to the rest of the United States. The second choropleth visualization allows the user to see the average affluence percentile of the users that have posted on Reddit in each state of the US. The relative shading also allows the user to compare the affluence of one state with the rest of the country.



