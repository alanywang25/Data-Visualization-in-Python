{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63266d5f-ca28-469e-9595-b11b1ca66e5b",
   "metadata": {},
   "source": [
    "# Combining Multiple Files of the Same Type\n",
    "\n",
    "This code is particularly helpful if you want to be able to merge a lot of files together into one dataframe, given that they are all named in the same pattern and they are all the same file type. \n",
    "\n",
    "This is the code that we used to merge 63 `.geo.tsv` files to get an entire dataframe with all of the information about 200+ million Reddit posts, which served as the base dataset that we merged parts of our other datasets to. We referenced this sample code from Github: https://github.com/ekapope/Combine-CSV-files-in-the-folder/blob/master/Combine_CSVs.py.\n",
    "\n",
    "For the purposes of this data manipulation demo, because of data privacy, we've subsetted 4 dataframes with 25 data observations each, all with fake usernames to replace the 'author' column. We will merge these 4 files in this demo into a combined file with 100 data observations that will be used later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d59eb75-7b50-4c2e-bf15-99926b9ef5fa",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Here we are importing the necessary libraries to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2192a737-d777-4ed8-a1a9-6e4faecc1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231512c-d442-4165-bd32-b2de3727f853",
   "metadata": {},
   "source": [
    "## Combine Files\n",
    "\n",
    "Since all of the files are formatted the same, we can combine them together into one file. We found that saving a file as a `.parquet` file was convenient for loading in the data later. \n",
    "\n",
    "The `os.getcwd()` method gets the current working directory that you are in, which should be inside the `data_wrangling` folder. However, to access the individual data files, we need to replace the current working directory with the directory that leads to the files. Once that has been done, we can go head and merge all of the files together into one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88cf075d-5c32-40f9-a9fa-24e2352c0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.getcwd()\n",
    "DATA_DIR = DATA_DIR.replace('data_wrangling', 'synthetic_data/combine_files')\n",
    "\n",
    "os.chdir(DATA_DIR)\n",
    "extension = 'parquet'\n",
    "all_filenames = [i for i in glob.glob('*_synthetic.{}'.format(extension))]\n",
    "\n",
    "combined_file = pd.concat([pd.read_parquet(f) for f in all_filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d4e060d-2855-4173-b6fd-03d0c68c9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_file.to_parquet(\"combined_posts_file.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
