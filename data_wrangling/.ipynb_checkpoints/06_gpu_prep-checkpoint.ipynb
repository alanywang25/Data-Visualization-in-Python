{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f591a5-0970-4aaf-af21-8b8324b2b9ba",
   "metadata": {},
   "source": [
    "# GPU Visualization Data Preparation\n",
    "\n",
    "This is the process that we went through to prepare our data for the GPU visualization (Worldwide Reddit Post Activity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e03f687-ceea-431c-90f2-05b46485127d",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "We are importing the necessary libraries to execute our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea05f61d-4814-45c3-a04c-b156044bd9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datashader as ds\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739c868-a22e-49d3-9719-683dc92c49e8",
   "metadata": {},
   "source": [
    "## Read in Dataset\n",
    "\n",
    "We are reading in our test synthetic dataset as a `.parquet` file that we previously did manipulations on.\n",
    "\n",
    "The `os.getcwd()` method gets the current working directory that you are in, which should be inside the `data_wrangling` folder. However, to access the data file, we need to replace the current working directory with the directory that leads to the file. Once that has been done, we can go head with reading in the data and performing the necessary data manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb6efb22-a182-42a3-904d-2b59aac255f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.getcwd()\n",
    "DATA_DIR = DATA_DIR.replace('data_wrangling', 'synthetic_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7dfe4d-8997-4347-ba82-40b4062a743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comb = pd.read_parquet(DATA_DIR + '/final_combinedsubclus.parquet') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd611b81-c088-4f01-96ea-821b8fd08f51",
   "metadata": {},
   "source": [
    "## Convert Hour Variable to Int\n",
    "\n",
    "Because we had extracted out the hour of day from a string, we needed to convert the hour of day to an int so that our multiselect tool for the GPU visualization would work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e6adae2-8d2f-4578-8696-46b3debada27",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comb['hour'] = new_comb['hour'].astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb48516-1a91-4594-bd87-2dea6e6a6546",
   "metadata": {},
   "source": [
    "## Mapping Day of the Week to Numbers\n",
    "\n",
    "In order for our day of the week dropdown to work, we needed to assign each day of the week to a number. Each day of the week was assigned to be a condition with a corresponding value, and the select method from the numpy library will match each day of the week to the corresponding number. This will set up the label map that will be used in the dropdown menu for the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "155f2dfd-4e54-4374-a4ca-65bc8087cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [(new_comb['day_of_week'] == 'Sunday'),\n",
    "             (new_comb['day_of_week'] == 'Monday'),\n",
    "             (new_comb['day_of_week'] == 'Tuesday'),\n",
    "             (new_comb['day_of_week'] == 'Wednesday'),\n",
    "             (new_comb['day_of_week'] == 'Thursday'),\n",
    "             (new_comb['day_of_week'] == 'Friday'),\n",
    "             (new_comb['day_of_week'] == 'Saturday')]\n",
    "\n",
    "values = [0, 1, 2, 3, 4, 5, 6]\n",
    "new_comb['day_as_num'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3e50f-a4fc-476e-9ca0-48a2591e4aaa",
   "metadata": {},
   "source": [
    "## Extract Certain Columns of Data\n",
    "\n",
    "To make a GPU visualization, we need our dataframe to be a `cudf` dataframe. In order to do this, we need to do a conversion. To make the conversion process more efficient, we've pulled only the columns that we want to use in the visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "971ecce3-36e5-450b-950c-520783c6c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file = new_comb[[\"long\", \"lat\", \"hour\", \"day_as_num\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d32afab-455b-4b70-96b1-035415883eec",
   "metadata": {},
   "source": [
    "## Convert Longitude/Latitude Points to Mercator Points\n",
    "\n",
    "Using the longitude/latitude point format that our data originally has, we were able to plot all of the points but the map would not properly display. So, we found a way to convert the points into Mercator format, and doing this conversion allowed for the map to load behind the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17711ea7-cf22-4274-b3bf-28599fb9260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "390f2d1d-4bcd-48ac-987d-6cf38628afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file.loc[:, 'long'], temp_file.loc[:, 'lat'] = ds.utils.lnglat_to_meters(temp_file.long,temp_file.lat) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf851a3-a4d4-4ee4-90b2-2800eecc57c5",
   "metadata": {},
   "source": [
    "## Save to Parquet File\n",
    "\n",
    "Now that all of the data has been prepared for the GPU visualization, we can save this dataframe as a parquet file that we can just read in once when we run the code in our notebook for the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c598a3cc-76c7-4a28-914d-ea935ff3dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file.to_parquet(DATA_DIR + '/gpufile_combinedsubclus.parquet') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
