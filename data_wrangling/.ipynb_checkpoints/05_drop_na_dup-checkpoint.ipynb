{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adc0705-4bb1-4bcc-9010-31355e31d646",
   "metadata": {},
   "source": [
    "# Data Cleaning: Dropping N/A and Duplicate Values\n",
    "\n",
    "Data might not always be perfect, and may contain observations that are missing values for variables, or may contain duplicate observations. In some cases, we want to able to clean up datasets by dropping these values, using methods from the `pandas` library.\n",
    "\n",
    "This is especially helpful for plotting visualizations using the `Python 3` kernel, because you will be visualizing less points and thus making the visualization load quicker. For example, for our affluence bubble map visualization, we cut down our large dataset from over 200 million observations to around 2 million observations by removing any observations with `NaN` values and any duplicate observations. We had to do this because the code we wanted to use to create this visualization needed the `geoviews` library, which the `rapids` kernel does not support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba719d-18c4-455a-aa3e-2d0f15eec8e0",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Here we are importing the necessary libraries for the data cleaning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715637d2-356e-4c05-91ab-b4c598588ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e904930-4f3a-446f-8cda-cba91c2b1d32",
   "metadata": {},
   "source": [
    "## Read In Data\n",
    "\n",
    "Read in the data that you would like to drop certain values for. The `os.getcwd()` method gets the current working directory that you are in, which should be inside the `data_wrangling` folder. However, to access the data file, we need to replace the current working directory with the directory that leads to the file. Once that has been done, we can go head with reading in the data and performing the necessary data manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de52cb5-17e5-4992-b31d-85d506277551",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.getcwd()\n",
    "DATA_DIR = DATA_DIR.replace('data_wrangling', 'synthetic_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3029461-f186-4cc3-b470-8567558dd574",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = pd.read_parquet(DATA_DIR + '/final_combinedsubclus.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c43495-c038-4f55-a205-52c2bcf0a22a",
   "metadata": {},
   "source": [
    "## Drop N/A Values\n",
    "\n",
    "We can drop `NaN` values using the `.dropna()` function. For more information, you can visit this link: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d751cc6-c4f9-4b0c-86aa-6a752c961ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = tester.dropna(how='any', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10245fd8-45a7-447f-9288-04ec4dd9784a",
   "metadata": {},
   "source": [
    "## Drop Duplicate Values\n",
    "\n",
    "We can drop duplicate values using the `.drop_duplicates()` function. For more information, you can visit this link: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad5d195d-1545-44ea-903b-36cb000d6cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f7df9-f0d7-49ed-9419-bf1de26bfb63",
   "metadata": {},
   "source": [
    "## Export as Parquet File\n",
    "\n",
    "Once you've dropped all of the values and gotten your dataset down to a smaller number of observations, you can save your dataframe as a `parquet` file so that you don't need to run this code each time you want to use this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "245a0dcd-8abb-40aa-977b-80e92344bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_parquet(DATA_DIR + '/cleaned_final_combinedsubclus.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
